"""
TexCut - OpenCV-Free Image Processing Module

This module provides image contour detection without requiring OpenCV.
Uses only libraries bundled with Blender: NumPy and Blender's image API.

To integrate into TexCut:
1. Copy this file to your addon directory
2. Import: from .texcut_no_opencv import analyze_alpha_channel
3. Replace the old OpenCV-based analyze_alpha_channel() calls

Author: Generated by Claude Code
Date: 2025-11-19
License: GPL-3.0-or-later (same as TexCut)
"""

import numpy as np
import bpy


def dilate_mask(mask, offset):
    """
    Binary dilation to expand mask boundaries.

    Pure NumPy implementation - works everywhere without dependencies.

    Args:
        mask: Binary mask (numpy array, dtype=uint8)
        offset: Number of pixels to expand

    Returns:
        Dilated mask (numpy array, dtype=uint8)
    """
    result = mask.copy().astype(bool)

    for _ in range(offset):
        padded = np.pad(result, 1, mode='constant', constant_values=False)
        dilated = result.copy()

        # Check all 8 neighbors
        dilated |= padded[:-2, 1:-1]   # top
        dilated |= padded[2:, 1:-1]    # bottom
        dilated |= padded[1:-1, :-2]   # left
        dilated |= padded[1:-1, 2:]    # right
        dilated |= padded[:-2, :-2]    # top-left
        dilated |= padded[:-2, 2:]     # top-right
        dilated |= padded[2:, :-2]     # bottom-left
        dilated |= padded[2:, 2:]      # bottom-right

        result = dilated

    return result.astype(np.uint8)


def find_boundary_pixels(mask):
    """
    Fast vectorized boundary pixel detection.

    Returns coordinates of pixels that are foreground with background neighbors.

    Args:
        mask: Binary mask (numpy array)

    Returns:
        Array of [y, x] coordinates of boundary pixels
    """
    # Pad to handle edges
    padded = np.pad(mask, 1, mode='constant', constant_values=0)

    # A boundary pixel is foreground with at least one background 4-neighbor
    is_fg = padded[1:-1, 1:-1].astype(bool)
    has_bg = (
        ~padded[:-2, 1:-1].astype(bool) |  # top
        ~padded[2:, 1:-1].astype(bool) |   # bottom
        ~padded[1:-1, :-2].astype(bool) |  # left
        ~padded[1:-1, 2:].astype(bool)     # right
    )

    boundary = is_fg & has_bg
    return np.column_stack(np.where(boundary))


def moore_neighbor_tracing(mask):
    """
    Moore neighbor tracing algorithm for contour extraction.

    Follows the boundary of the foreground region in the mask.

    Args:
        mask: Binary mask (numpy array, dtype=uint8)

    Returns:
        List of (x, y) tuples representing the contour points
    """
    height, width = mask.shape

    # Find starting point (first boundary pixel, top-left scan)
    boundary_pixels = find_boundary_pixels(mask)

    if len(boundary_pixels) == 0:
        return []

    # Start with topmost, then leftmost pixel
    start_y, start_x = boundary_pixels[0]

    contour = []
    y, x = start_y, start_x

    # 8-connected neighborhood (clockwise from North)
    moore_neighbors = [
        (-1, 0), (-1, 1), (0, 1), (1, 1),
        (1, 0), (1, -1), (0, -1), (-1, -1)
    ]

    # Find initial backtrack direction (find first background pixel)
    backtrack_idx = 0
    for i, (dy, dx) in enumerate(moore_neighbors):
        ny, nx = y + dy, x + dx
        if 0 <= ny < height and 0 <= nx < width:
            if not mask[ny, nx]:
                backtrack_idx = i
                break

    current_idx = backtrack_idx
    max_iterations = height * width

    for iteration in range(max_iterations):
        contour.append((x, y))

        # Search for next boundary pixel (start two steps back from current direction)
        found = False
        search_start = (current_idx - 2) % 8

        for i in range(8):
            check_idx = (search_start + i) % 8
            dy, dx = moore_neighbors[check_idx]
            ny, nx = y + dy, x + dx

            if 0 <= ny < height and 0 <= nx < width:
                if mask[ny, nx]:
                    # Found next boundary pixel
                    y, x = ny, nx
                    current_idx = check_idx

                    # Check if we've returned to start
                    if (y, x) == (start_y, start_x) and len(contour) > 2:
                        return contour

                    found = True
                    break

        if not found:
            break

    return contour


def simplify_contour(points, epsilon):
    """
    Ramer-Douglas-Peucker algorithm for contour simplification.

    Reduces the number of points while preserving the shape.
    Iterative implementation to avoid stack overflow.

    Args:
        points: List of (x, y) tuples
        epsilon: Distance threshold for point removal

    Returns:
        Simplified list of (x, y) tuples
    """
    if len(points) < 3:
        return points

    def point_line_distance(point, line_start, line_end):
        """Perpendicular distance from point to line segment."""
        px, py = point
        x1, y1 = line_start
        x2, y2 = line_end

        dx = x2 - x1
        dy = y2 - y1

        if dx == 0 and dy == 0:
            return np.hypot(px - x1, py - y1)

        return abs(dy * px - dx * py + x2 * y1 - y2 * x1) / np.hypot(dx, dy)

    # Iterative implementation using a stack
    stack = [(0, len(points) - 1)]
    keep = {0, len(points) - 1}

    while stack:
        start_idx, end_idx = stack.pop()

        if end_idx - start_idx < 2:
            continue

        # Find point with maximum distance
        max_dist = 0
        max_idx = start_idx

        for i in range(start_idx + 1, end_idx):
            dist = point_line_distance(points[i], points[start_idx], points[end_idx])
            if dist > max_dist:
                max_dist = dist
                max_idx = i

        # Keep point if distance exceeds threshold
        if max_dist > epsilon:
            keep.add(max_idx)
            stack.append((start_idx, max_idx))
            stack.append((max_idx, end_idx))

    # Return kept points in order
    return [points[i] for i in sorted(keep)]


def analyze_alpha_channel(image_path, threshold=0.01, boundary_offset=8):
    """
    Analyze image alpha channel and return outline points.

    This is a drop-in replacement for the OpenCV-based version.
    Uses only NumPy + Blender's image API (no external dependencies).

    Args:
        image_path: Path to the image file
        threshold: Alpha threshold for considering a pixel opaque (0-1)
        boundary_offset: Number of pixels to expand the boundary (default 8)

    Returns:
        Tuple of (normalized_contour, width, height)
        where normalized_contour is a list of (x, y) tuples in -0.5 to 0.5 range
    """
    # Load image with Blender's API
    img = bpy.data.images.load(image_path, check_existing=True)
    width, height = img.size

    # Get pixels as numpy array (RGBA format)
    pixels = np.array(img.pixels[:])

    # Reshape to (height, width, 4) - Blender stores pixels as flat RGBA array
    pixels = pixels.reshape((height, width, 4))

    # Flip vertically - Blender stores pixels bottom-to-top, we need top-to-bottom
    pixels = np.flipud(pixels)

    # Get alpha channel (4th component)
    if img.depth == 32:  # Has alpha
        alpha = (pixels[:, :, 3] * 255).astype(np.uint8)
    else:
        # No alpha channel - create full opacity mask
        alpha = np.full((height, width), 255, dtype=np.uint8)

    # Create binary mask
    mask = (alpha > (threshold * 255)).astype(np.uint8)

    # Dilate mask to expand boundary
    if boundary_offset > 0:
        mask = dilate_mask(mask, boundary_offset)

    # Find contour using Moore tracing
    contour = moore_neighbor_tracing(mask)

    if not contour or len(contour) < 3:
        print(f"TexCut: No contour found or contour too small")
        return [], width, height

    # Simplify contour (same epsilon as OpenCV version)
    perimeter = len(contour)
    epsilon = 0.001 * perimeter
    simplified = simplify_contour(contour, epsilon)

    print(f"TexCut: Found contour with {len(contour)} points, simplified to {len(simplified)} points")

    # Normalize to -0.5 to 0.5 range (same as OpenCV version)
    normalized_contour = []
    for x, y in simplified:
        norm_x = (x / width) - 0.5
        norm_y = 0.5 - (y / height)  # Flip Y axis for Blender
        normalized_contour.append((norm_x, norm_y))

    return normalized_contour, width, height


# For testing - note: this module must be imported within Blender to work
# as it uses bpy (Blender Python API)
